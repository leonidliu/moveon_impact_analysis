---
title: "6 ITT Regression"
author: "Andy Zack"
date: "`r Sys.Date()`"
format: html
self-contained: true
editor: source
execute:
  echo: true
---

This code runs the ITT regression on the 800K subset of the data. We are using this smaller dataset because even though there are fewer people in it, the contact rate was so much higher that it should produce more statistical power. The experiment is still severely underpowered. The final part of this script outputs the numbers that can be plugged into the [AI Power Calculator](https://analystinstitute.org/power-calculator/) to see this.

Given that this is an ITT analysis, it does not produce separate analyses for postcard vs. regular phone vs GOTV phone. There are also no subgroup analyses due to the fact that it is so underpowered and that the topline result is null.

## Load Packages

```{r packages}
#| warning: false

library(tidyverse)
library(aws.s3)
library(here)
library(kableExtra)
library(scales)
library(marginaleffects)
library(broom)
```

## Other Setup

```{r other_setup}
Sys.setenv("AWS_ACCESS_KEY_ID" = Sys.getenv("TMC_s3_access_key"),
           "AWS_SECRET_ACCESS_KEY" = Sys.getenv("TMC_s3_secret_key"))

bucket = "tmc-research-projects"
```

## Load Data

```{r load_data}
clean_df <- s3read_using(
  FUN = read_rds,
  bucket = bucket,
  object = "p080_moveon_impact_analysis/clean_df.rds")
```

## Clean Data

This section drops the \~3,000 people that could not be matched to the voterfile. We could instead just count them as not voted. It is so few people that it probably does not matter either way.

This section also cleans up some of the factors that have no people in them. That is what `droplevels()` does. I think this should make the `marginaleffects::avg_predictions()` run smoothly without error.

```{r drop_unmatched}
model_df <- clean_df %>%
  filter(!is.na(vb_tsmart_exact_track)) %>%
  select(treat,
         voted_24,
         gender,
         age,
         target_geography_state,
         voted_22,
         voted_20,
         voted_p22,
         voted_p20,
         race,
         ts_tsmart_presidential_general_turnout_score,
         ts_tsmart_presidential_general_turnout_score_sq,
         ts_tsmart_partisan_score,
         ts_tsmart_partisan_score_sq,
         urbanicity,
         ts_tsmart_college_graduate_score) %>%
  droplevels()
  

nrow(clean_df) 
nrow(model_df)
nrow(clean_df)  - nrow(model_df)
```

## Impute Missing

Age is the only column with some missing data. I impute the mean here. This could be done in the data-cleaning step, but it might only be needed in this script.

```{r impute_missing}
model_df %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "column", values_to = "na_count") %>%
  filter(na_count > 0) %>%
  kable()

# impute age with mean age for the ~ 350 cases where it is missing
model_df$age[is.na(model_df$age)] <- mean(model_df$age, na.rm = T)
```

## Run Model

```{r run_model}
itt_model <- glm(formula = voted_24 ~ .,
                 data = model_df,
                 family = "binomial")

tidy(itt_model) %>% kable()
```

## Get Model Results

```{r get_model_results}
# calculate treatment and control group sizes for table
n_treat <- sum(model_df[["treat"]] == 1)
n_control <- sum(model_df[["treat"]] == 0)

# calculate mcfadden adjusted r^2
mcfadden_adj_r2 <- as.numeric(pscl::pR2(itt_model)["McFadden"])

# run marginal effects
ame_treat <- avg_slopes(itt_model, variables = "treat", conf_level = .9)
preds <- avg_predictions(itt_model, variables = "treat", conf_level = .9)

# clean up all results into one pretty table
itt_regression_results <- bind_rows(ame_treat, preds) %>%
  as_tibble() %>%
  transmute(regression_type = "logistic", 
         condition = case_when(treat == 0 ~ "control",
                               treat == 1 ~ "treatment",
                               TRUE ~ "treatment - control"),
         n = case_when(treat == 0 ~ n_control,
                       treat == 1 ~ n_treat),
         predicted_prob = estimate,
         se = std.error,
         ci_low_90 = conf.low,
         ci_high_90 = conf.high,
         p_value = p.value,
         adj_rsq = mcfadden_adj_r2) 

kable(itt_regression_results)
```

## Save Regression Results

```{r save_results}
s3write_using(x = itt_regression_results, 
              FUN = saveRDS, 
              object = "p080_moveon_impact_analysis/regression_results.rds", 
              bucket = "tmc-research-projects")
```

## Power Calculation

This section does not actually run the power calculation but gets all the numbers you need to run it on the AI tool.

```{r power_calc}
# universe size
nrow(clean_df)

# outcome collection rate
round(1 - sum(is.na(clean_df$vb_tsmart_exact_track)) / nrow(clean_df), digits = 2) * 100

# percent in treatment group
round(100*sum(clean_df$treat==1) / nrow(clean_df))

# turnout rate in control
clean_df %>%
  filter(treat == 0) %>%
  summarise(turnout_rate = 100 * mean(voted_24)) %>%
  pull(turnout_rate) %>%
  round()

# contact rate
clean_df %>%
  filter(treat == 1) %>%
  summarise(contact_rate = 100* mean(exp_contacted)) %>%
  pull(contact_rate) %>%
  round()

# predictive power of covariates
round(mcfadden_adj_r2, 2)

# power of experiment
80

# confidence
90
```

When these numbers are plugged into the AI tool, you'd expect to reliably measure an effect of 4.4pp.
